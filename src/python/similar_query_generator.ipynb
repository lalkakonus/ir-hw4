{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Similar query generator",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSi8NmBwHhTL",
        "colab_type": "text"
      },
      "source": [
        "Установка необходимых библиотек\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l0L-GXN0pJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install fasttext\n",
        "!pip install tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZziXzhqDHeUL",
        "colab_type": "text"
      },
      "source": [
        "Монтирование диска Google Drive для загрузк и харанения  данных.\n",
        "\n",
        "**ВНИМАНИЕ** для доступа к данным необходимо выполнить следующие действия:\n",
        "\n",
        "1. Перейти по [ссылке](https://drive.google.com/drive/folders/1MnoxVXjG8o8kL0SS14E3YzbZmCovsGpR?usp=sharing)\n",
        "2. Создать ярлык на данную директорию в своём Google Drive. Для этого нажмите на название директории а затем на \"Добавить ярлык на Диск\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEDscjko0ti5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkhp-YlyHjzj",
        "colab_type": "text"
      },
      "source": [
        "Импорт необходимых компонентов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD_lT4ab0sfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fasttext import FastText\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "import xml.etree.ElementTree as Etree\n",
        "import requests\n",
        "import regex as re\n",
        "from random import randint, random\n",
        "\n",
        "prefix = Path(\"/content/gdrive/My Drive/Kononov_NLP\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2GQ5JQgHpE8",
        "colab_type": "text"
      },
      "source": [
        "Выбор и загрузка предобученной модели для генерации векторного представления слов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCqT8SEs0y_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# name, alias = \"ft_native_300_ru_wiki_lenta_lower_case\", \"wiki\"\n",
        "# name, alias = \"ft_native_300_ru_twitter_nltk_word_tokenize\", \"twitter\"\n",
        "name, alias = \"cc.ru.300\", \"original\"\n",
        "model = FastText.load_model(str(prefix / \"FastText/{}.bin\".format(name)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoSQ6QqkIr_J",
        "colab_type": "text"
      },
      "source": [
        "Генерация синонимичных слов состоит из двух частей:\n",
        "1. Генерация на основе ближайших соседей слова в пространстве эмбеддингов\n",
        "2. Генерация на основе словаря Yandex Dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAZLXLYXU2Xl",
        "colab_type": "text"
      },
      "source": [
        "Создание корпуса - множества всех слов, входящих в запросы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH6poJ_JJ-QH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "queries_df = pd.read_csv(prefix / \"queries.tsv\", sep=\"\\t\", index_col=0)\n",
        "\n",
        "corpus = set()\n",
        "for query in queries_df[\"text\"]:\n",
        "  corpus.update(query.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ8oc7YqJICz",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "**1. Генерация на основе ближайших соседей слова в пространстве \n",
        "эмбеддингов**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T42-15IXJSJ7",
        "colab_type": "text"
      },
      "source": [
        "Установка порога, слова, имеющие похожесть ниже которого нас не интересуют"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KRWaMdi4BfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "threshold = 0.8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbbEU5me3dqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_path = prefix / \"simialr_queries_words_nn.tsv\"\n",
        "with open(output_path, \"w\") as output_stream:\n",
        "  output_stream.write(\"word_a\\tword_b\\tscore\\n\")  \n",
        "  for word in tqdm(corpus, position=0, leave=True):\n",
        "    sinonims = model.get_nearest_neighbors(word, k=5)\n",
        "    for item in sinonims: \n",
        "      if item[0] > threshold:\n",
        "        output_stream.write(\"{}\\t{}\\t{:05.3f}\\n\".format(word, item[1], item[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlRkcQGFLdtv",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "**2. Генерация на основе синонимов из Yandex Dictionary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3uMSnTuMnIC",
        "colab_type": "text"
      },
      "source": [
        "Функция добавьте сгенерованные на [сайте](https://yandex.ru/dev/dictionary/) api ключи в переменную api_keys."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jOf-Xi8ME48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url_base = \"https://dictionary.yandex.net/api/v1/dicservice/lookup?key={}&lang=ru-en&text={}\"\n",
        "api_key= [\"dict.1.1.20200614T093641Z.6ef4f758e1bde788.6bcb115395a67b382dbbf07cf9e017f0562f5da4\",\n",
        "          \"dict.1.1.20200614T093949Z.1159baedcb8fba61.da66fba1ca1dc871a4b99d6d70ea322ded9fa130\",\n",
        "          \"dict.1.1.20200614T094544Z.28e27a08835d6ea1.8b417d5ae635087b9ebd6c72aa9eec85733d6f2c\"]\n",
        "OK_RESPONSE_CODE = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM4JiYexNPKM",
        "colab_type": "text"
      },
      "source": [
        "Функция отправки запросов и обработки результатов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Arel_IUBMNeG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def send_request(self, word):\n",
        "  idx = randint(0, len(self.api_key) - 1)\n",
        "  url = self.url_base.format(self.api_key[idx], word)\n",
        "  try:\n",
        "    response = requests.get(url)\n",
        "  except Exception as err:\n",
        "    print(err)\n",
        "    return [\"ERROR\", ]\n",
        "  if response.status_code != self.OK_RESPONSE_CODE:\n",
        "    print(response.text)\n",
        "    print(\"Warning: response status code {}\".format(response.status_code))\n",
        "    header = \"; \".join([str(key) + \" : \" + str(value) for key, value in response.headers.items()])\n",
        "    print(\"Response header: \\n{}\".format(header))\n",
        "    return [\"BAD_CODE\", ]\n",
        "  root = Etree.fromstring(response.text)\n",
        "  result = []\n",
        "  if len(root) > 1:\n",
        "    for i, spellResult in enumerate(root[1].findall(\"*.mean\")):\n",
        "      result.append(spellResult[0].text)\n",
        "    return result\n",
        "  else:\n",
        "    return [\"NONE\", ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz2RBpnaN5FC",
        "colab_type": "text"
      },
      "source": [
        "Генерация синонимов для всех слов корпуса"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lKBEcbBMPQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dictionary = dict()\n",
        "for word in tqdm(corpus):\n",
        "    syns = self._send_request(word)\n",
        "  if syns:\n",
        "    dictionary[word] = syns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bBeB4jiQ2CX",
        "colab_type": "text"
      },
      "source": [
        "Подсчёт похожести для каждой пары синонимов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-04L1YHv6k_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = []\n",
        "for key, value in syn.items():\n",
        "    data += [(key, x) for x in value]\n",
        "df = pd.DataFrame(data, columns=[\"word_a\", \"word_b\"])\n",
        "df = df[df[\"word_b\"] != \"NONE\"]\n",
        "df = df[df[\"word_b\"] != \"ERROR\"]\n",
        "df = df.assign(score=np.zeros(syns.index.size, dtype=float))\n",
        "\n",
        "for key, group in tqdm(syns.groupby(\"word_a\")):\n",
        "  word_emb = model.get_word_vector(key).reshape(1, -1)\n",
        "  words_emb = np.array(group[\"word_b\"].apply(model.get_sentence_vector).to_list())\n",
        "  syns.loc[group.index, \"score\"] = cosine_similarity(word_emb, words_emb).reshape(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoXtWnGXQ7Sx",
        "colab_type": "text"
      },
      "source": [
        "Отделение синонимов похожесть которых превышает заданный порог и cохранение результатов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4CWWdVxkaHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "threshold = 0.3\n",
        "\n",
        "df = df[df[\"score\"] > threshold]\n",
        "df = df.sort_values(\"word_a\")\n",
        "\n",
        "df.to_csv(prefix / \"simialr_queries_words_ya.tsv\", sep=\"\\t\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkEv9KYrUR3R",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "**Генерация похожих запросов**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGHAV1MVUVEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "queries = pd.read_csv(prefix / \"queries.tsv\", sep=\"\\t\", index_col=0)\n",
        "\n",
        "nn_df = pd.read_csv(prefix / \"simialr_queries_words_nn.tsv\", sep=\"\\t\")\n",
        "ya_df = pd.read_csv(prefix / \"simialr_queries_words_ya.tsv\", sep=\"\\t\")\n",
        "similarity_df = pd.concat([nn_df, ya_df], ignore_index=True)\n",
        "\n",
        "similarity_df[\"word_a\"] = similarity_df[\"word_a\"].apply(str.lower)\n",
        "similarity_df[\"word_b\"] = similarity_df[\"word_b\"].apply(str.lower).apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
        "similarity_df.drop_duplicates(subset=[\"word_a\", \"word_b\"], inplace=True)\n",
        "similarity_df = similarity_df[similarity_df[\"word_a\"] != similarity_df[\"word_b\"]]\n",
        "similarity_df = similarity_df[similarity_df[\"word_a\"].str.isalpha()]\n",
        "\n",
        "similar_groups = similarity_df.groupby(\"word_a\")\n",
        "\n",
        "\n",
        "with open(prefix / \"wider_queries.tsv\", \"w\") as output_stream:\n",
        "    valid_set = set(similarity_df[\"word_a\"].unique())\n",
        "    for key, row in tqdm(list(queries.iterrows())):\n",
        "        words = row[\"text\"].split()\n",
        "        new_queries = set()\n",
        "        new_queries.add(tuple([row[\"text\"],  1]))\n",
        "        for i in range(20):\n",
        "            new_query = []\n",
        "            score = 1\n",
        "            for word in words:\n",
        "                if word in valid_set:\n",
        "                    sim_words = similar_groups.get_group(word)\n",
        "                    idx = randint(0, sim_words.index.size - 1)\n",
        "                    sim_word = sim_words[\"word_b\"].values[idx]\n",
        "                    if random() < 0.3:\n",
        "                        score *= sim_words[\"similarity\"].values[idx]\n",
        "                        new_query.append(sim_word)\n",
        "                    else:\n",
        "                        new_query.append(word)\n",
        "                else:\n",
        "                    new_query.append(word)\n",
        "            new_queries.add(tuple([\" \".join(new_query), score]))\n",
        "        for item in new_queries:\n",
        "            output_stream.write(\"{}\\t{}\\t{:04.2f}\\n\".format(key, item[0], item[1]))\n",
        "\n",
        "    raw_queries = pd.read_csv(prefix / \"queries.tsv\", sep=\"\\t\", index_col=0)\n",
        "    for key, row in raw_queries.iterrows():\n",
        "        output_stream.write(\"{}\\t{}\\t1.00\\n\".format(key, row[\"text\"]))\n",
        "\n",
        "df = pd.read_csv(prefix / \"wider_queries.tsv\", sep=\"\\t\", index_col=0, names=[\"text\", \"score\"])\n",
        "df = df.drop_duplicates(subset=[\"text\"]).sort_index()\n",
        "df.to_csv(prefix / \"wider_queries.tsv\", sep=\"\\t\", index_label=\"query_id\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}